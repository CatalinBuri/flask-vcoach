import os
import json
from flask import Flask, request, jsonify
from flask_cors import CORS
from google import genai
from dotenv import load_dotenv

# ------------------------------------------------------------
#  √éNCƒÇRCARE VARIABILE DE MEDIU »òI INI»öIALIZARE
# ------------------------------------------------------------
load_dotenv()
app = Flask(__name__)

# ------------------------------------------------------------
#  CONFIGURARE CORS SIGUR PENTRU PROD + DEV
# ------------------------------------------------------------
ALLOWED_ORIGINS = [
    "https://www.pixelplayground3d.ro",
    "https://pixelplayground3d.ro",
    "https://cvcoach-ai.vercel.app",
    "http://localhost:5173",
    "http://127.0.0.1:5173"
]

CORS(
    app,
    origins=ALLOWED_ORIGINS,
    supports_credentials=True,
    allow_headers=["Content-Type", "Authorization"],
    methods=["GET", "POST", "OPTIONS"]
)

@app.after_request
def after_request(response):
    """AsigurƒÉ headere CORS corecte pentru toate rƒÉspunsurile."""
    origin = request.headers.get("Origin")
    if origin in ALLOWED_ORIGINS:
        response.headers["Access-Control-Allow-Origin"] = origin
    response.headers["Access-Control-Allow-Methods"] = "GET, POST, OPTIONS"
    response.headers["Access-Control-Allow-Headers"] = "Content-Type, Authorization"
    return response

@app.route("/<path:path>", methods=["OPTIONS"])
def options_handler(path):
    """RƒÉspuns global la cererile OPTIONS (preflight)."""
    response = jsonify({"status": "preflight ok"})
    origin = request.headers.get("Origin")
    if origin in ALLOWED_ORIGINS:
        response.headers["Access-Control-Allow-Origin"] = origin
    response.headers["Access-Control-Allow-Methods"] = "GET, POST, OPTIONS"
    response.headers["Access-Control-Allow-Headers"] = "Content-Type, Authorization"
    return response

# ------------------------------------------------------------
#  INITIALIZARE CLIENT GEMINI
# ------------------------------------------------------------
API_KEY = os.environ.get("GEMINI_API_KEY")
try:
    if not API_KEY:
        print("‚ùå EROARE: LipsƒÉ GEMINI_API_KEY √Æn fi»ôierul .env")
        gemini_client = None
    else:
        gemini_client = genai.Client(api_key=API_KEY)
except Exception as e:
    print(f"‚ùå Eroare la ini»õializarea clientului Gemini: {e}")
    gemini_client = None

# ------------------------------------------------------------
#  FUNC»öIE UTILITARƒÇ: SAFE JSON PARSING
# ------------------------------------------------------------
def safe_json_extract(text):
    """ParseazƒÉ √Æn siguran»õƒÉ un rƒÉspuns JSON, chiar dacƒÉ are delimitatori Markdown."""
    if not text:
        raise ValueError("RƒÉspuns AI gol.")
    txt = text.strip()

    if txt.startswith("```json"):
        txt = txt.replace("```json", "").strip()
    if txt.endswith("```"):
        txt = txt[:-3].strip()

    try:
        return json.loads(txt)
    except json.JSONDecodeError:
        try:
            start = txt.index("{")
            end = txt.rindex("}") + 1
            return json.loads(txt[start:end])
        except Exception as e:
            raise ValueError(f"Nu s-a putut extrage JSON-ul din text: {e}\n{text[:300]}...")

# ------------------------------------------------------------
#  RUTƒÇ DE VERIFICARE
# ------------------------------------------------------------
@app.route("/", methods=["GET"])
def home():
    return jsonify({"status": "OK", "message": "Flask VCoach API online ‚úÖ"}), 200

# ------------------------------------------------------------
#  RUTA 1: ANALIZA CV + JOB DESCRIPTION
# ------------------------------------------------------------
@app.route("/analyze-cv", methods=["POST", "OPTIONS"])
def analyze_cv():
    if request.method == "OPTIONS":
        return jsonify({"status": "preflight ok"}), 200

    if not gemini_client:
        return jsonify({"error": "Gemini client neini»õializat"}), 500

    data = request.get_json()
    cv_text = data.get("cv_text", "").strip()
    job_text = data.get("job_text", "").strip()

    if not cv_text or not job_text:
        return jsonify({"error": "LipsƒÉ text CV sau descriere job"}), 400

    prompt = f"""
    E»ôti un analist HR AI. ComparƒÉ textul CV-ului cu descrierea jobului »ôi oferƒÉ o evaluare completƒÉ.

    CV:
    {cv_text}

    JOB DESCRIPTION:
    {job_text}

    ReturneazƒÉ √Æn format JSON STRICT:
    {{
      "compatibility_percent": 0-100,
      "feedback_markdown": "Feedback detaliat, √Æn format Markdown, cu puncte tari »ôi recomandƒÉri."
    }}
    """

    try:
        response = gemini_client.models.generate_content(
            model="gemini-2.5-flash",
            contents=prompt
        )
        return jsonify(safe_json_extract(response.text)), 200
    except Exception as e:
        print(f"‚ùå Eroare la analiza CV: {e}")
        return jsonify({"error": "Analiza CV a e»ôuat.", "details": str(e)}), 500

# ------------------------------------------------------------
#  RUTA 2: GENERARE JOB QUERIES
# ------------------------------------------------------------
@app.route("/generate-job-queries", methods=["POST"])
def generate_job_queries():
    if not gemini_client:
        return jsonify({"error": "Gemini API indisponibil"}), 503

    data = request.get_json()
    cv_text = data.get("cv_text", "").strip()

    if not cv_text:
        return jsonify({"error": "LipsƒÉ text CV √Æn cerere"}), 400

    prompt = f"""
    E»ôti un asistent de carierƒÉ AI. Extrage din CV profesia »ôi competen»õele principale »ôi genereazƒÉ 5 interogƒÉri de cƒÉutare relevante pentru joburi.

    Format JSON STRICT:
    {{
      "queries": ["interogare 1", "interogare 2", "interogare 3", "interogare 4", "interogare 5"]
    }}

    CV:
    {cv_text}
    """

    try:
        response = gemini_client.models.generate_content(
            model="gemini-2.5-flash",
            contents=prompt
        )
        return jsonify(safe_json_extract(response.text)), 200
    except Exception as e:
        print(f"‚ùå Eroare la generarea interogƒÉrilor job: {e}")
        return jsonify({"error": "Eroare la generarea interogƒÉrilor", "details": str(e)}), 500

# ------------------------------------------------------------
#  RUTA 3: GENERARE FAQ (√éNTREBƒÇRI)
# ------------------------------------------------------------
@app.route('/generate-beginner-faq', methods=['POST'])
def generate_beginner_faq():
    if not gemini_client:
        return jsonify({"error": "Serviciul AI nu este disponibil"}), 503

    data = request.get_json()
    cv_text = data.get('cv_text', '').strip()

    if not cv_text or cv_text == 'GENERIC_FAQ_MODE':
        context_prompt = "GenereazƒÉ 5 √ÆntrebƒÉri standard pentru candida»õi entry-level."
    else:
        context_prompt = f"GenereazƒÉ 5 √ÆntrebƒÉri bazate pe CV-ul urmƒÉtor:\n{cv_text}"

    prompt = f"""
    E»ôti un recrutor AI. CreeazƒÉ 5 √ÆntrebƒÉri frecvente (FAQ) »ôi explica»õia lor.

    Format JSON STRICT:
    {{
      "faq": [
        {{
          "question": "√éntrebarea 1?",
          "explanation": "ScurtƒÉ explica»õie a inten»õiei recrutorului."
        }}
      ]
    }}

    {context_prompt}
    """

    try:
        response = gemini_client.models.generate_content(
            model='gemini-2.5-flash',
            contents=prompt
        )
        return jsonify(safe_json_extract(response.text)), 200
    except Exception as e:
        print(f"‚ùå Eroare FAQ: {e}")
        return jsonify({"error": "Eroare la generarea FAQ", "details": str(e)}), 500

# ------------------------------------------------------------
#  RUTA 4: ANALIZA RƒÇSPUNSURILOR FAQ
# ------------------------------------------------------------
@app.route('/analyze-faq-answers', methods=['POST'])
def analyze_faq_answers():
    if not gemini_client:
        return jsonify({"error": "Clientul Gemini nu este ini»õializat"}), 500

    data = request.get_json()
    faq_data = data.get('faq_data')

    if not faq_data or not isinstance(faq_data, list):
        return jsonify({"error": "Format invalid pentru 'faq_data'."}), 400

    item = faq_data[0]
    prompt = f"""
    E»ôti un antrenor de interviu. AnalizeazƒÉ rƒÉspunsul utilizatorului la √Æntrebarea urmƒÉtoare.

    √éNTREBAREA: {item.get('question', 'N/A')}
    EXPLICA»öIA INTEN»öIEI: {item.get('explanation', 'N/A')}
    RƒÇSPUNS UTILIZATOR: {item.get('user_answer', 'N/A')}

    ReturneazƒÉ √Æn format JSON STRICT:
    {{
      "analysis_results": [
        {{
          "question": "{item.get('question', 'N/A')}",
          "user_answer": "{item.get('user_answer', 'N/A')}",
          "evaluation": {{
            "nota_finala": 0-10,
            "claritate": 0-10,
            "relevanta": 0-10,
            "structura": 0-10,
            "feedback": "Feedback constructiv √Æn Markdown"
          }}
        }}
      ]
    }}
    """

    try:
        response = gemini_client.models.generate_content(
            model='gemini-2.5-flash',
            contents=prompt
        )
        return jsonify(safe_json_extract(response.text)), 200
    except Exception as e:
        print(f"‚ùå Eroare analizƒÉ FAQ: {e}")
        return jsonify({"error": "Analiza rƒÉspunsului FAQ a e»ôuat", "details": str(e)}), 500

# ------------------------------------------------------------
#  RUTA 5: GENERARE RAPORT FINAL
# ------------------------------------------------------------
@app.route('/generate-final-report', methods=['POST'])
def generate_final_report():
    if not gemini_client:
        return jsonify({"error": "Gemini API neconfigurat"}), 500

    data = request.json
    faq_history = data.get('faq_history', [])

    if not faq_history:
        return jsonify({"error": "Istoricul FAQ este gol."}), 400

    history_text = ""
    for idx, entry in enumerate(faq_history):
        q = entry.get('question_data', {}).get('question', 'N/A')
        a = entry.get('user_answer', 'N/A')
        note = entry.get('analysis', {}).get('evaluation', {}).get('nota_finala', 'N/A')
        feedback = entry.get('analysis', {}).get('evaluation', {}).get('feedback', 'N/A')
        history_text += f"--- √éntrebarea {idx+1} (Nota: {note}/10) ---\n√éntrebare: {q}\nRƒÉspuns: {a}\nFeedback: {feedback}\n\n"

    prompt = f"""
    E»ôti un coach AI. GenereazƒÉ un raport final sumariz√¢nd performan»õa candidatului.

    FORMAT JSON STRICT:
    {{
      "final_score": "Nota medie (ex: 8.2)",
      "summary": "SintezƒÉ generalƒÉ √Æn Markdown",
      "key_strengths": ["Punct forte 1", "Punct forte 2", "Punct forte 3"],
      "areas_for_improvement": ["Arie 1", "Arie 2", "Arie 3"],
      "next_steps_recommendation": "RecomandƒÉri practice (Markdown)"
    }}

    ---
    ISTORIC:
    {history_text}
    """

    try:
        response = gemini_client.models.generate_content(
            model='gemini-2.5-flash',
            contents=prompt
        )
        return jsonify(safe_json_extract(response.text)), 200
    except Exception as e:
        print(f"‚ùå Eroare raport final: {e}")
        return jsonify({"error": "Generarea raportului final a e»ôuat", "details": str(e)}), 500

# ------------------------------------------------------------
#  START SERVER
# ------------------------------------------------------------
if __name__ == "__main__":
    print("üöÄ Flask VCoach server running on port 5000...")
    app.run(host="0.0.0.0", port=5000)
