# server_vcoach.py
import os
import json
from flask import Flask, request, jsonify
from flask_cors import CORS
from google import genai
from dotenv import load_dotenv

# --------------------------
# √éncarcƒÉ variabilele de mediu (.env)
load_dotenv()
API_KEY = os.environ.get("GEMINI_API_KEY")

# --------------------------
# Ini»õializare Flask
app = Flask(__name__)
CORS(app, resources={
    r"/*": {
        "origins": ["https://www.pixelplayground3d.ro"],
        "methods": ["GET", "POST", "OPTIONS"],
        "allow_headers": ["Content-Type", "Authorization"],
    }
})

# --------------------------
# Logging minimal pentru debugging
@app.before_request
def log_request():
    print(f"[{request.method}] {request.path}  |  from: {request.headers.get('Origin', 'local')}")

# --------------------------
# Client Gemini
try:
    if not API_KEY:
        print("‚ùå EROARE: GEMINI_API_KEY lipse»ôte!")
        gemini_client = None
    else:
        gemini_client = genai.Client(api_key=API_KEY)
        print("‚úÖ Conexiune Gemini ini»õializatƒÉ corect.")
except Exception as e:
    print(f"‚ùå Eroare la ini»õializarea Gemini: {e}")
    gemini_client = None

# --------------------------
# UTILITƒÇ»öI
def safe_json_extract(text):
    if not text:
        raise ValueError("Text gol primit de la AI.")
    full_text = text.strip()
    if full_text.startswith('```json'):
        full_text = full_text.replace('```json', '', 1).strip()
    if full_text.endswith('```'):
        full_text = full_text[:-3].strip()
    try:
        return json.loads(full_text)
    except json.JSONDecodeError:
        try:
            start_index = full_text.index('{')
            end_index = full_text.rindex('}') + 1
            return json.loads(full_text[start_index:end_index])
        except Exception as e:
            raise ValueError(f"Eroare la extragerea JSON: {e}. Text: {full_text[:500]}...")

# --------------------------
# ROUTE: Analiza CV
@app.route('/analyze-cv', methods=['POST'])
def analyze_cv():
    if gemini_client is None:
        return jsonify({"error": "AI indisponibil"}), 503

    data = request.get_json()
    cv_text = data.get('cv_text', '').strip()
    job_text = data.get('job_text', '').strip()

    if not cv_text or not job_text:
        return jsonify({"error": "CV »ôi Job Description sunt necesare."}), 400

    prompt = f"""
    EvalueazƒÉ compatibilitatea CV-ului cu Job-ul urmƒÉtor:
    CV: {cv_text}
    Job Description: {job_text}
    ReturneazƒÉ JSON strict cu:
    {{
      "compatibility_percent": 0-100,
      "feedback_markdown": "Feedback detaliat √Æn Markdown"
    }}
    """
    try:
        response = gemini_client.models.generate_content(
            model='gemini-2.5-flash',
            contents=prompt
        )
        result = safe_json_extract(response.text)
        return jsonify(result), 200
    except Exception as e:
        return jsonify({"error": "AnalizƒÉ CV e»ôuatƒÉ", "details": str(e)}), 500

# --------------------------
# ROUTE: Generare Job Queries
@app.route('/generate-job-queries', methods=['POST'])
def generate_job_queries():
    if gemini_client is None:
        return jsonify({"error": "AI indisponibil"}), 503

    cv_text = request.get_json().get('cv_text', '').strip()
    if not cv_text:
        return jsonify({"error": "CV este necesar."}), 400

    prompt = f"""
    GenereazƒÉ 5-10 interogƒÉri optimizate pentru job hunt bazate pe acest CV:
    {cv_text}
    ReturneazƒÉ JSON cu cheia 'queries', fiecare element fiind o interogare text.
    """
    try:
        response = gemini_client.models.generate_content(
            model='gemini-2.5-flash',
            contents=prompt
        )
        result = safe_json_extract(response.text)
        return jsonify(result), 200
    except Exception as e:
        return jsonify({"error": "Generare Job Queries e»ôuatƒÉ", "details": str(e)}), 500

# --------------------------
# ROUTE: Generare Cover Letter
@app.route('/generate-cover-letter', methods=['POST'])
def generate_cover_letter():
    if gemini_client is None:
        return jsonify({"error": "AI indisponibil"}), 503

    data = request.get_json()
    cv_text = data.get('cv_text', '')
    job_summary = data.get('job_summary', '')

    prompt = f"""
    GenereazƒÉ o scrisoare de inten»õie profesionistƒÉ:
    CV: {cv_text}
    Job Summary: {job_summary}
    ReturneazƒÉ JSON cu cheia 'cover_letter' »ôi textul scrisorii.
    """
    try:
        response = gemini_client.models.generate_content(
            model='gemini-2.5-flash',
            contents=prompt
        )
        result = safe_json_extract(response.text)
        return jsonify(result), 200
    except Exception as e:
        return jsonify({"error": "Generare Cover Letter e»ôuatƒÉ", "details": str(e)}), 500

# --------------------------
# ROUTE: Optimize LinkedIn Profile
@app.route('/optimize-linkedin-profile', methods=['POST'])
def optimize_linkedin_profile():
    if gemini_client is None:
        return jsonify({"error": "AI indisponibil"}), 503

    cv_text = request.get_json().get('cv_text', '')
    prompt = f"""
    OferƒÉ recomandƒÉri detaliate pentru optimizarea profilului LinkedIn bazat pe acest CV:
    {cv_text}
    ReturneazƒÉ JSON cu cheia 'linkedin_tips', o listƒÉ de sugestii.
    """
    try:
        response = gemini_client.models.generate_content(
            model='gemini-2.5-flash',
            contents=prompt
        )
        result = safe_json_extract(response.text)
        return jsonify(result), 200
    except Exception as e:
        return jsonify({"error": "Optimizare LinkedIn e»ôuatƒÉ", "details": str(e)}), 500

# --------------------------
# ROUTE: Generare Beginner FAQ
@app.route('/generate-beginner-faq', methods=['POST'])
def generate_beginner_faq():
    if gemini_client is None:
        return jsonify({"error": "AI indisponibil"}), 503

    cv_text = request.get_json().get('cv_text', '').strip()
    prompt_context = f"GenereazƒÉ 5 √ÆntrebƒÉri FAQ pentru √ÆncepƒÉtori bazate pe CV:\n{cv_text}" if cv_text else "GenereazƒÉ 5 √ÆntrebƒÉri FAQ standard pentru entry-level."

    prompt = f"""
    E»ôti un recrutor AI. {prompt_context}
    ReturneazƒÉ DOAR JSON cu cheia "questions", fiecare obiect av√¢nd:
    {{
      "question": "√éntrebarea X?",
      "explanation": "ScurtƒÉ explica»õie a inten»õiei recrutorului (Markdown, max 5 propozi»õii)"
    }}
    """
    try:
        response = gemini_client.models.generate_content(
            model='gemini-2.5-flash',
            contents=prompt
        )
        result = safe_json_extract(response.text)
        return jsonify(result), 200
    except Exception as e:
        return jsonify({"error": "Generare Beginner FAQ e»ôuatƒÉ", "details": str(e)}), 500

# --------------------------
# ROUTE: Evaluate Answer (Comparative)
@app.route('/evaluate-answer', methods=['POST'])
def evaluate_answer():
    if gemini_client is None:
        return jsonify({"error": "AI indisponibil"}), 503

    data = request.get_json()
    question = data.get('question')
    user_answer = data.get('answer')
    previous_answer = data.get('previous_answer')
    previous_evaluation = data.get('previous_evaluation')

    prompt = f"""
    AnalizeazƒÉ rƒÉspunsul utilizatorului:
    √éntrebare: {question}
    RƒÉspuns: {user_answer}
    Istoric rƒÉspuns anterior: {previous_answer}
    Evaluare anterioarƒÉ: {previous_evaluation}
    ReturneazƒÉ JSON strict cu:
    {{
      "current_evaluation": {{
          "nota_finala": 0-10,
          "claritate": 0-10,
          "relevanta": 0-10,
          "structura": 0-10,
          "feedback": "Feedback detaliat √Æn Markdown"
      }},
      "comparative_feedback": "Feedback comparativ cu rƒÉspunsul anterior"
    }}
    """
    try:
        response = gemini_client.models.generate_content(
            model='gemini-2.5-flash',
            contents=prompt
        )
        result = safe_json_extract(response.text)
        return jsonify(result), 200
    except Exception as e:
        return jsonify({"error": "Evaluare rƒÉspuns e»ôuatƒÉ", "details": str(e)}), 500

# --------------------------
# ROUTE: Generate Final Report
@app.route('/generate-report', methods=['POST'])
def generate_report():
    if gemini_client is None:
        return jsonify({"error": "AI indisponibil"}), 503

    data = request.get_json()
    faq_history = data.get('history', [])
    job_summary = data.get('summary', '')
    cv_text = data.get('cv_text', '')

    if not faq_history:
        return jsonify({"error": "Istoricul FAQ este gol"}), 400

    history_text = ""
    for idx, entry in enumerate(faq_history):
        q = entry.get('question', 'N/A')
        a = entry.get('answer', 'N/A')
        note = entry.get('evaluation', {}).get('nota_finala', 'N/A')
        feedback = entry.get('evaluation', {}).get('feedback', 'N/A')
        history_text += f"--- √éntrebarea {idx+1} (Nota: {note}/10) ---\nQ: {q}\nA: {a}\nFeedback: {feedback}\n\n"

    prompt = f"""
    E»ôti un Career Coach AI. Folose»ôte istoricul FAQ pentru a genera un raport final.
    FORMAT JSON STRICT:
    {{
      "final_score": "medie din scoruri",
      "summary": "SintezƒÉ generalƒÉ √Æn Markdown",
      "key_strengths": ["3 puncte forte cheie"],
      "areas_for_improvement": ["3 arii de √ÆmbunƒÉtƒÉ»õire"],
      "next_steps_recommendation": "RecomandƒÉri pentru urmƒÉtorii pa»ôi"
    }}
    ISTORIC FAQ:\n{history_text}
    JOB SUMMARY:\n{job_summary}
    CV TEXT:\n{cv_text}
    """
    try:
        response = gemini_client.models.generate_content(
            model='gemini-2.5-flash',
            contents=prompt
        )
        result = safe_json_extract(response.text)
        return jsonify(result), 200
    except Exception as e:
        return jsonify({"error": "Generare raport final e»ôuatƒÉ", "details": str(e)}), 500

# --------------------------
# PORNIRE SERVER
if __name__ == '__main__':
    print("üöÄ Server Flask pornit pe http://0.0.0.0:5000/")
    app.run(host='0.0.0.0', port=5000, debug=True)
