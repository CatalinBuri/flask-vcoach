# server_vcoach_robust.py
import os
import json
import traceback
from flask import Flask, request, jsonify
from flask_cors import CORS
from google import genai
from dotenv import load_dotenv

# --------------------------
# ÃncarcÄƒ variabilele de mediu (.env)
load_dotenv()
API_KEY = os.environ.get("GEMINI_API_KEY")

# --------------------------
# IniÈ›ializare Flask
app = Flask(__name__)
CORS(app, resources={r"/*": {"origins": "*"}})

# --------------------------
# Logging minimal pentru debugging
@app.before_request
def log_request():
    print(f"[{request.method}] {request.path} | from: {request.headers.get('Origin', 'local')}")

# --------------------------
# IniÈ›ializare client Gemini
gemini_client = None
try:
    if not API_KEY:
        print("âŒ EROARE: GEMINI_API_KEY lipseÈ™te!")
    else:
        gemini_client = genai.Client(api_key=API_KEY)
        print("âœ… Conexiune Gemini iniÈ›ializatÄƒ corect.")
except Exception as e:
    print(f"âŒ Eroare la iniÈ›ializarea Gemini: {e}")

# --------------------------
# UTILITÄ‚ÈšI

# 1. FuncÈ›ia Ã®mbunÄƒtÄƒÈ›itÄƒ pentru extracÈ›ia JSON (Ã®nlocuieÈ™te vechiul safe_json_extract)
def safe_json_extract(text):
    if not text:
        raise ValueError("Text gol primit pentru extracÈ›ia JSON.")
    full_text = text.strip()
    
    # 1. EliminÄƒ ```json È™i ```
    if full_text.startswith('```json'):
        full_text = full_text.replace('```json', '', 1).strip()
    if full_text.endswith('```'):
        full_text = full_text[:-3].strip()
        
    try:
        # 2. ÃncearcÄƒ direct
        return json.loads(full_text)
    except json.JSONDecodeError as e_loads:
        # 3. ÃncearcÄƒ sÄƒ gÄƒseascÄƒ {...}
        try:
            # GÄƒseÈ™te primul '{' È™i ultimul '}'
            start_index = full_text.index('{')
            end_index = full_text.rindex('}') + 1
            return json.loads(full_text[start_index:end_index])
        except Exception as e_extract:
            # Eroarea finalÄƒ (include detalii mai bune)
            raise ValueError(f"Eroare la extragerea JSON: {e_extract} (Origine: {e_loads}). Text: {full_text[:500]}...")

# 2. FuncÈ›ie pentru a obÈ›ine textul brut de la AI 
def call_gemini_raw(prompt):
    if gemini_client is None:
        return {"error": "Eroare de configurare server", "details": "Clientul AI nu a putut fi iniÈ›ializat (API Key lipsÄƒ/invalidÄƒ)."}
    try:
        response = gemini_client.models.generate_content(
            model="gemini-2.5-flash",
            contents=prompt
            # Eliminat: timeout=25
        )
        # ReturneazÄƒ textul brut
        return response.text
    # Aceste exceptii sunt acum definite datorita Pasului 1
    except DeadlineExceededError as e:
        return {"error": "Eroare de comunicare AI (Timeout)", "details": "Serviciul AI a depÄƒÈ™it timpul maxim de rÄƒspuns (25s). ÃncercaÈ›i din nou.", "code": 504}
    except APIError as e:
        # GestioneazÄƒ alte erori API
        return {"error": "Eroare API Gemini", "details": str(e), "code": 500}
    except Exception as e:
        # Eroare de ReÈ›ea sau altceva.
        return {"error": "Eroare de comunicare AI (NecunoscutÄƒ)", "details": str(e), "code": 500}
# 3. FuncÈ›ie pentru a obÈ›ine JSON 
def call_gemini_json(prompt):
    raw_text = call_gemini_raw(prompt)
    
    # VerificÄƒ dacÄƒ raw_text a returnat o eroare de configurare/comunicare
    if isinstance(raw_text, dict) and "error" in raw_text:
        return raw_text 
    
    try:
        # ÃncearcÄƒ sÄƒ extragÄƒ JSON din textul brut
        return safe_json_extract(raw_text)
    except ValueError as e:
        # Eroare de extracÈ›ie JSON
        return {"error": "Eroare la extragerea JSON", "details": str(e), "raw_text_received": raw_text[:500]}

# --------------------------
# ROUTE: Procesare descriere job (RAW)
@app.route('/process-text', methods=['POST'])
def process_text():
    data = request.get_json()
    job_text = data.get('text', '').strip()

    if not job_text:
        return jsonify({"error": "Descrierea postului (text) este obligatorie."}), 400

    prompt = (
        f"AnalizeazÄƒ aceastÄƒ descriere de job: '{job_text}'. "
        "Extrage informaÈ›iile cheie (rol, cerinÈ›e, responsabilitÄƒÈ›i) È™i oferÄƒ un rezumat "
        "scurt È™i clar, de maxim 3-4 paragrafe."
    )

    try:
        # ğŸ¯ FOLOSIM: call_gemini_raw
        raw_result = call_gemini_raw(prompt) 
        
        if isinstance(raw_result, dict) and "error" in raw_result:
            return jsonify(raw_result), 500

        # ReturnÄƒm textul Ã®nvelit Ã®n JSON
        return jsonify({"processed_text": raw_result}), 200 
    
    except Exception as e:
        traceback.print_exc()
        print("âŒ Eroare gravÄƒ Ã®n /process-text:", str(e))
        return jsonify({"error": "Eroare internÄƒ neprevÄƒzutÄƒ", "details": str(e)}), 500

# --------------------------
# ROUTE: Generare Ã®ntrebÄƒri interviu (JSON)
@app.route('/generate-questions', methods=['POST'])
def generate_questions():
    data = request.get_json()
    cv_text = data.get('cv_text', '')
    job_summary = data.get('job_summary', '')
    prompt = (
        f"EÈ™ti un recrutor AI. Pe baza acestui rezumat al postului: {job_summary} È™i CV: {cv_text}, "
        "genereazÄƒ 5 Ã®ntrebÄƒri de interviu comportamentale unice, relevante È™i de nivel avansat. "
        "ReturneazÄƒ JSON strict: {'questions': [{'question': 'Ãntrebarea 1?'}, {'question': 'Ãntrebarea 2?'}, ...]}."
    )
    # ğŸ¯ FOLOSIM: call_gemini_json
    result = call_gemini_json(prompt)
    return jsonify(result), 200 if "error" not in result else 500

# --------------------------
# ROUTE: AnalizÄƒ CV vs Job (JSON)
@app.route('/analyze-cv', methods=['POST'])
def analyze_cv():
    data = request.get_json()
    cv_text = data.get('cv_text', '').strip()
    job_text = data.get('job_text', '').strip()
    if not cv_text or not job_text:
        return jsonify({"error": "CV È™i Job Description sunt necesare."}), 400

    prompt = f"""
    EvalueazÄƒ compatibilitatea CV-ului cu Job-ul:
    CV: {cv_text}
    Job Description: {job_text}
    ReturneazÄƒ JSON strict cu:
    {{
      "compatibility_percent": 0-100,
      "feedback_markdown": "Feedback detaliat Ã®n Markdown"
    }}
    """
    # ğŸ¯ FOLOSIM: call_gemini_json
    result = call_gemini_json(prompt)
    return jsonify(result), 200 if "error" not in result else 500

# --------------------------
# ROUTE: Generare interogÄƒri job hunt (JSON)
@app.route('/generate-job-queries', methods=['POST'])
def generate_job_queries():
    cv_text = request.get_json().get('cv_text', '').strip()
    if not cv_text:
        return jsonify({"error": "CV este necesar."}), 400
    prompt = f"""
    GenereazÄƒ 5-10 interogÄƒri optimizate pentru job hunt bazate pe acest CV:
    {cv_text}
    ReturneazÄƒ JSON cu cheia 'queries', fiecare element fiind o interogare text.
    """
    # ğŸ¯ FOLOSIM: call_gemini_json
    result = call_gemini_json(prompt)
    return jsonify(result), 200 if "error" not in result else 500

# --------------------------
# ROUTE: Generare Cover Letter (JSON)
@app.route('/generate-cover-letter', methods=['POST'])
def generate_cover_letter():
    data = request.get_json()
    cv_text = data.get('cv_text', '')
    job_summary = data.get('job_summary', '')
    prompt = f"""
    GenereazÄƒ o scrisoare de intenÈ›ie profesionistÄƒ:
    CV: {cv_text}
    Job Summary: {job_summary}
    ReturneazÄƒ JSON cu cheia 'cover_letter' È™i textul scrisorii.
    """
    # ğŸ¯ FOLOSIM: call_gemini_json
    result = call_gemini_json(prompt)
    return jsonify(result), 200 if "error" not in result else 500

# --------------------------
# ROUTE: Optimizare profil LinkedIn (JSON)
@app.route('/optimize-linkedin-profile', methods=['POST'])
def optimize_linkedin_profile():
    cv_text = request.get_json().get('cv_text', '')
    prompt = f"""
    OferÄƒ recomandÄƒri detaliate pentru optimizarea profilului LinkedIn bazat pe acest CV:
    {cv_text}
    ReturneazÄƒ JSON cu cheia 'linkedin_tips', o listÄƒ de sugestii.
    """
    # ğŸ¯ FOLOSIM: call_gemini_json
    result = call_gemini_json(prompt)
    return jsonify(result), 200 if "error" not in result else 500

# --------------------------
# ROUTE: Generare Beginner FAQ (JSON)
@app.route('/generate-beginner-faq', methods=['POST'])
def generate_beginner_faq():
    cv_text = request.get_json().get('cv_text', '').strip()
    prompt_context = f"GenereazÄƒ 5 Ã®ntrebÄƒri FAQ pentru Ã®ncepÄƒtori bazate pe CV:\n{cv_text}" if cv_text else "GenereazÄƒ 5 Ã®ntrebÄƒri FAQ standard pentru entry-level."
    prompt = f"""
    EÈ™ti un recrutor AI. {prompt_context}
    ReturneazÄƒ DOAR JSON cu cheia "questions", fiecare obiect avÃ¢nd:
    {{
      "question": "Ãntrebarea X?",
      "explanation": "ScurtÄƒ explicaÈ›ie Ã®n Markdown"
    }}
    """
    # ğŸ¯ FOLOSIM: call_gemini_json
    result = call_gemini_json(prompt)
    return jsonify(result), 200 if "error" not in result else 500

# --------------------------
# ROUTE: Evaluare rÄƒspuns utilizator (JSON)
@app.route('/evaluate-answer', methods=['POST'])
def evaluate_answer():
    data = request.get_json()
    question = data.get('question')
    user_answer = data.get('answer')
    history = data.get('history', []) # LuÄƒm tot istoricul
    
    # PregÄƒtire context din istoric (opÈ›ional, dacÄƒ AI-ul Ã®l foloseÈ™te)
    history_text = "\n".join([f"Q: {h.get('question')}\nA: {h.get('answer')}\n" for h in history])

    # SeteazÄƒ promptul pentru AI
    prompt = f"""
    EvalueazÄƒ rÄƒspunsul utilizatorului la urmÄƒtoarea Ã®ntrebare.
    CONTEXT INTERVIU (Istoric):
    {history_text}
    
    Ãntrebare curentÄƒ: {question}
    RÄƒspuns utilizator: {user_answer}
    
    ReturneazÄƒ JSON strict cu:
    {{
      "current_evaluation": {{"nota_finala": 0-10,"claritate": 0-10,"relevanta": 0-10,"structura": 0-10,"feedback": "Feedback detaliat Ã®n Markdown"}},
      "comparative_feedback": {{"feedback": "Feedback evolutiv, bazat pe istoric (dacÄƒ existÄƒ) Ã®n Markdown."}}
    }}
    """
    # ğŸ¯ FOLOSIM: call_gemini_json
    result = call_gemini_json(prompt)
    return jsonify(result), 200 if "error" not in result else 500

# --------------------------
# ROUTE: Generare raport final (JSON)
@app.route('/generate-report', methods=['POST'])
def generate_report():
    data = request.get_json()
    faq_history = data.get('history', [])
    job_summary = data.get('job_summary', '')
    cv_text = data.get('cv_text', '')
    if not faq_history:
        return jsonify({"error": "Istoricul interviului este gol"}), 400

    history_text = ""
    for idx, entry in enumerate(faq_history):
        q = entry.get('question', 'N/A')
        a = entry.get('answer', 'N/A')
        eval_dict = entry.get('evaluation', {})
        note = eval_dict.get('nota_finala', 'N/A')
        feedback = eval_dict.get('feedback', 'N/A')
        history_text += f"--- Ãntrebarea {idx+1} (Nota: {note}/10) ---\nQ: {q}\nA: {a}\nFeedback: {feedback}\n\n"

    prompt = f"""
    EÈ™ti un Career Coach AI. FoloseÈ™te istoricul pentru a genera un raport final.
    FORMAT JSON STRICT:
    {{
      "final_score": "medie din scoruri",
      "summary": "SintezÄƒ generalÄƒ Ã®n Markdown",
      "key_strengths": ["3 puncte forte"],
      "areas_for_improvement": ["3 arii de Ã®mbunÄƒtÄƒÈ›ire"],
      "next_steps_recommendation": "RecomandÄƒri pentru urmÄƒtorii paÈ™i"
    }}
    ISTORIC INTERVIU:\n{history_text}
    JOB SUMMARY:\n{job_summary}
    CV TEXT:\n{cv_text}
    """
    # ğŸ¯ FOLOSIM: call_gemini_json
    result = call_gemini_json(prompt)
    return jsonify(result), 200 if "error" not in result else 500

# --------------------------
# ROUTE: Rezultate HTML STAR (RAW - returneazÄƒ text HTML)
@app.route('/coach-results-html', methods=['POST'])
def coach_results_html():
    data = request.get_json()
    history = data.get('history', [])
    if not history:
        return "<h3>Nu existÄƒ rÄƒspunsuri de procesat</h3>", 400

    html_content = """
    <html lang='ro'>
    <head>
        <meta charset='UTF-8'>
        <title>Coach Feedback STAR</title>
        <style>
            body { font-family: Arial, sans-serif; background: #f4f7f6; padding: 20px; color: #2c3e50; }
            h1 { text-align: center; color: #2980b9; }
            .entry { background: #fff; padding: 15px; margin: 15px 0; border-radius: 10px; box-shadow: 0 3px 10px rgba(0,0,0,0.08); }
            .question { font-weight: bold; color: #34495e; }
            .user-answer, .star-answer { margin-top: 10px; padding: 10px; border-radius: 6px; background: #ecf0f1; white-space: pre-wrap; }
            .star-answer { border-left: 5px solid #2ecc71; background: #e8f6ef; }
        </style>
    </head>
    <body>
        <h1>Rezultate Coach - Versiune STAR</h1>
    """
    for idx, entry in enumerate(history):
        question = entry.get('question', 'Ãntrebare lipsÄƒ')
        user_answer = entry.get('answer', 'RÄƒspuns lipsÄƒ')
        
        prompt = f"""
        Ãntrebarea: {question}
        RÄƒspunsul utilizatorului: {user_answer}
        Te rog sÄƒ rescrii acest rÄƒspuns Ã®ntr-o versiune optimizatÄƒ STAR (Situation, Task, Action, Result).
        ReturneazÄƒ DOAR textul rÄƒspunsului optimizat.
        """
        # ğŸ¯ FOLOSIM: call_gemini_raw
        star_answer_result = call_gemini_raw(prompt)
        
        star_answer = star_answer_result if isinstance(star_answer_result, str) else star_answer_result.get("details", "Eroare generare STAR")
        
        html_content += f"""
        <div class='entry'>
            <div class='question'>Ãntrebarea {idx+1}: {question}</div>
            <div class='user-answer'><strong>RÄƒspunsul tÄƒu:</strong>\n{user_answer}</div>
            <div class='star-answer'><strong>RÄƒspuns STAR optimizat:</strong>\n{star_answer}</div>
        </div>
        """
    html_content += "</body></html>"
    return html_content, 200

# --------------------------
# ROUTE: STAR next (RAW - returneazÄƒ textul STAR Ã®n JSON)
@app.route('/coach-next', methods=['POST'])
def coach_next():
    data = request.get_json()
    question = data.get('question')
    user_answer = data.get('user_answer')
    if not question or not user_answer:
        return jsonify({"error": "Ãntrebare È™i rÄƒspuns obligatorii"}), 400

    prompt = f"""
    Ãntrebarea: {question}
    RÄƒspunsul utilizatorului: {user_answer}
    Te rog sÄƒ rescrii acest rÄƒspuns Ã®ntr-o versiune optimizatÄƒ STAR.
    ReturneazÄƒ DOAR textul rÄƒspunsului optimizat.
    """
    # ğŸ¯ FOLOSIM: call_gemini_raw
    star_answer_result = call_gemini_raw(prompt)

    if isinstance(star_answer_result, dict) and "error" in star_answer_result:
        return jsonify(star_answer_result), 500

    star_answer = star_answer_result

    return jsonify({
        "question": question,
        "user_answer": user_answer,
        "star_answer": star_answer
    }), 200

# --------------------------
# PORNIRE SERVER
if __name__ == '__main__':
    print("ğŸš€ Server Flask robust pornit pe [http://0.0.0.0:5000/](http://0.0.0.0:5000/)")
    # RecomandÄƒm sÄƒ foloseÈ™ti gunicorn sau un alt server WSGI pentru producÈ›ie.
    # DacÄƒ rulezi local, lasÄƒ app.run.
    # app.run(host='0.0.0.0', port=5000, debug=True)
    # Pentru Render, de obicei se foloseÈ™te un entry point gunicorn, dar lÄƒsÄƒm app pentru testare localÄƒ.
    pass



